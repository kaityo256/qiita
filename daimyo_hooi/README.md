# 大名行列をHOOIでTucker分解してみる

## はじめに

線形代数には、特異値分解(Singular Value Decomposition, SVD)という操作があり、行列の近似に使われています。詳しくは[大名行列を特異値分解してみる](https://qiita.com/kaityo256/items/78b16c58228e131f8144)」を参照してください。SVDによる行列の低ランク近似は、フロベニウスノルムの意味で最良近似になっています。さて、行列だけでなく、足がたくさんある高階のテンソルも近似したい、というニーズがあります。テンソルは、元のテンソルと同じ本数だが、次元が低い足を持つコアテンソルと、コアテンソルのそれぞれの足の次元を増やす復元行列の組み合わせで分解され、この分解をTucker分解と呼びます。テンソルをTucker分解した時、どのようにすれば最良近似となるかは不明瞭です。前記事「[大名行列をTucker分解してみる](https://qiita.com/kaityo256/items/2e3f45377a6b9760f3e0)」では、SVDを素直にテンソルに適用したHigher Order SVD (HOSVD)を使ってTucker分解してみましたが、これは最良近似になっていないことが知られています。本稿では、イテレーションにより近似精度を改善するHigher Order Orthogonal Iteration of tensors (HOOI)を適用し、HOSVDの結果比べてみましょう。

## Tucker分解とは

Tucker分解は、太い足を持つテンソルを、細い足を持つコアテンソルと、細い足から太い足に戻す復元行列に分解するものです。

![Tucker分解](tucker.png)

復元行列は直交行列になっており、転置を取ると「太い(次元が大きい)足」を「細い(次元が低い)足」に絞る圧縮行列になります。元のテンソルの足にそれぞれの圧縮行列をつけるとコアテンソルが得られます。

![コアテンソル](core.png)

したがってTucker分解とは、「テンソルが与えられた時、各足に対応する復元/圧縮行列を、足の本数だけ求めなさい」という問題になります。

さて、元のテンソルの足に圧縮行列をかけたものがコアテンソルで、コアテンソルの足に復元行列をかけたものが近似テンソルです。まとめて描いて見るとこんな感じになります。

![コアテンソルと近似テンソル](full.png)

つまり、元のテンソルの太い足を、途中で細く絞ることで低ランク近似するのがTucker分解です。ペアになっている三角形はお互いに転置(随伴)なので、足の本数だけこの三角形を求めましょう、というのがTucker分解です。


